{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivanshs9/making-malai/blob/main/rag-pdf-tables/parse_summarize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6d466cc-aa8b-4baf-a80a-fef01921ca8d",
      "metadata": {
        "id": "b6d466cc-aa8b-4baf-a80a-fef01921ca8d"
      },
      "source": [
        "## Semi-structured RAG\n",
        "\n",
        "Many documents contain a mixture of content types, including text and tables.\n",
        "\n",
        "Semi-structured data can be challenging for conventional RAG for at least two reasons:\n",
        "\n",
        "* Text splitting may break up tables, corrupting the data in retrieval\n",
        "* Embedding tables may pose challenges for semantic similarity search\n",
        "\n",
        "This cookbook shows how to perform RAG on documents with semi-structured data:\n",
        "\n",
        "* We will use [Unstructured](https://unstructured.io/) to parse both text and tables from documents (PDFs).\n",
        "* We will use the [multi-vector retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector) to store raw tables, text along with table summaries better suited for retrieval.\n",
        "* We will use [LCEL](https://python.langchain.com/docs/expression_language/) to implement the chains used.\n",
        "\n",
        "The overall flow is here:\n",
        "\n",
        "![MVR.png](attachment:7b5c5a30-393c-4b27-8fa1-688306ef2aef.png)\n",
        "\n",
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5740fc70-c513-4ff4-9d72-cfc098f85fef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5740fc70-c513-4ff4-9d72-cfc098f85fef",
        "outputId": "2dd6576d-84e1-4200-9eea-92543fb8f69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.11)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-unstructured in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (5.3.0)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.21)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.24 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.24)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.5.23)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.115.6)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (24.1.0)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (43.0.3)\n",
            "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (0.2.0)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (0.28.1)\n",
            "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (1.0.6)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (1.6.0)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (5.1.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (2.8.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (1.0.0)\n",
            "Requirement already satisfied: typing-inspect<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client) (0.9.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.24 (from langchain)\n",
            "  Downloading langchain_core-0.3.25-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.3-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: onnxruntime<=1.19.2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from langchain-unstructured) (1.19.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.2)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.0.20241016)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.34.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.4)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: tokenizers<=0.20.3,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.20.3)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.66.6)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.12)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client) (1.17.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.41.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.24->langchain) (1.33)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (5.29.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.13.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.8.2->unstructured-client) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<0.10.0,>=0.9.0->unstructured-client) (1.0.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client) (2.22)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.24->langchain) (3.0.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.9)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client) (1.2.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.26.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (14.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<=1.19.2,>=1.17.0->langchain-unstructured) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.1)\n",
            "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.12-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.25-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.3-py3-none-any.whl (27 kB)\n",
            "Downloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: httpx-sse, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.24\n",
            "    Uninstalling langchain-core-0.3.24:\n",
            "      Successfully uninstalled langchain-core-0.3.24\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.2\n",
            "    Uninstalling langchain-text-splitters-0.3.2:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.11\n",
            "    Uninstalling langchain-0.3.11:\n",
            "      Successfully uninstalled langchain-0.3.11\n",
            "Successfully installed httpx-sse-0.4.0 langchain-0.3.12 langchain-community-0.3.12 langchain-core-0.3.25 langchain-text-splitters-0.3.3 pydantic-settings-2.7.0\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain langchain-chroma unstructured-client langchain-community langchain-unstructured pydantic lxml langchainhub"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44349a83-e1dc-4eed-ba75-587f309d8c88",
      "metadata": {
        "id": "44349a83-e1dc-4eed-ba75-587f309d8c88"
      },
      "source": [
        "The PDF partitioning used by Unstructured will use:\n",
        "\n",
        "* `tesseract` for Optical Character Recognition (OCR)\n",
        "*  `poppler` for PDF rendering and processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f7880871-4949-4ea2-aed8-540a09188a41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7880871-4949-4ea2-aed8-540a09188a41",
        "outputId": "1e589240-af6c-4c8c-d385-7db1904d47a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 3s (1,689 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 123633 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libarchive-dev libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libarchive-dev libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 3,743 kB of archives.\n",
            "After this operation, 16.0 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libarchive-dev amd64 3.6.0-1ubuntu1.3 [581 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libleptonica-dev amd64 1.82.0-3build1 [1,562 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libtesseract-dev amd64 4.1.1-2.1build1 [1,600 kB]\n",
            "Fetched 3,743 kB in 3s (1,321 kB/s)\n",
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 123680 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.3_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "Preparing to unpack .../libleptonica-dev_1.82.0-3build1_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.82.0-3build1) ...\n",
            "Selecting previously unselected package libtesseract-dev:amd64.\n",
            "Preparing to unpack .../libtesseract-dev_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Setting up libleptonica-dev (1.82.0-3build1) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.3) ...\n",
            "Setting up libtesseract-dev:amd64 (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 1s (139 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123813 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "! apt-get install poppler-utils\n",
        "! pip install pytesseract"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c24efa9-b6f6-4dc2-bfe3-70819ba3ef75",
      "metadata": {
        "id": "7c24efa9-b6f6-4dc2-bfe3-70819ba3ef75"
      },
      "source": [
        "## Data Loading\n",
        "\n",
        "### Partition PDF tables and text\n",
        "\n",
        "Apply to the [`LLaMA2`](https://arxiv.org/pdf/2307.09288.pdf) paper.\n",
        "\n",
        "We use the Unstructured [`partition_pdf`](https://unstructured-io.github.io/unstructured/core/partition.html#partition-pdf), which segments a PDF document by using a layout model.\n",
        "\n",
        "This layout model makes it possible to extract elements, such as tables, from pdfs.\n",
        "\n",
        "We also can use `Unstructured` chunking, which:\n",
        "\n",
        "* Tries to identify document sections (e.g., Introduction, etc)\n",
        "* Then, builds text blocks that maintain sections while also honoring user-defined chunk sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "62cf502b-407d-4645-a72c-24498fd55130",
      "metadata": {
        "id": "62cf502b-407d-4645-a72c-24498fd55130"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content\"\n",
        "output_path = f'{base_path}/output'\n",
        "\n",
        "filename=\"r04 sub1.pdf\"\n",
        "pdf_langs=['jpn']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3867a654-61ba-4759-9a64-de953a429ced",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3867a654-61ba-4759-9a64-de953a429ced",
        "outputId": "d61f52b9-36f6-47e1-f903-35e961ea66de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:unstructured-client:'split_pdf_cache_tmp_data' does not exist. Using default value '/tmp'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type': 'CompositeElement', 'element_id': '482eac2054285106253eb19d05c4c00e', 'text': '運転免許統計（令和４年版）補足資料１\\n\\n警察庁交通局運転免許課\\n\\n目 次', 'metadata': {'filetype': 'application/pdf', 'languages': ['jpn'], 'page_number': 1, 'orig_elements': 'eJy1k9tu2zAMhl8l0HVs6Cxq77CiQHsXF4EOdOLBsY1E3hoUe/dJTjOgQzagxXojkL9+WqQ/cPNCsMcDDmnbRfJlRTgHSalxFTqDlVRMV156qJTn0WopUUZP1itywOSiSy7XvJAwjsfYDS7hacl7dx7ntN1jt9unrHAhbK55lX90Me2zyrSSWZ3GbkilbrMRnNdmvTJU1uxpvfqda1urkjMhaC1uCUtFVsjpfEp4KJPcd8/YP0wuIPmZLyImDKkbh23o3em0nY6jzzZaG2UFZEPb9ZjOEy6191/J0vCwm91umWpDvk0DKU9MWdkO88HjsUxRPp7wucxJmtlS6ZsZEHkzKyZjjp1gzWyiYSWm0MxtW06JKLNHQigKKzGafBouLx6b/RDzLUQv8hmCaWatrF38rDR47ffOHY8udd/xsTSSO/oTq7ZccM9C5T34SlrAyjswFYCOUukgKTOfhlUxKBiZ0armBdtVAA61XDgyAbW9qVyKPopWMPXf0ILXOkPysS2ogBWEThbkzGUl/8O/4wfn+fuABWgDFb6ivOyhpFg5plSFAaloWWToPw8Ys7psFRfXNXvNDVxy4Opmvvj/ieqDJPhbEkYjrvIueP5mCx671Odnnn4B321rjw==', 'filename': 'r04 sub1.pdf'}}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from typing import Any\n",
        "from google.colab import userdata\n",
        "from unstructured_client import UnstructuredClient\n",
        "from unstructured_client.models import shared, errors\n",
        "\n",
        "client = UnstructuredClient(\n",
        "    api_key_auth=userdata.get(\"UNSTRUCTURED_API_KEY\"),\n",
        "    server_url=userdata.get(\"UNSTRUCTURED_API_URL\"),\n",
        ")\n",
        "\n",
        "req = {\n",
        "    \"partition_parameters\": {\n",
        "        \"files\": {\n",
        "            \"content\": open(f'{base_path}/{filename}', \"rb\"),\n",
        "            \"file_name\": filename,\n",
        "        },\n",
        "        # Post processing to aggregate text once we have the title\n",
        "        \"chunking_strategy\": shared.ChunkingStrategy.BY_TITLE,\n",
        "        \"strategy\": shared.Strategy.HI_RES,\n",
        "        \"languages\": pdf_langs,\n",
        "        # Chunking params to aggregate text blocks\n",
        "        # Attempt to create a new chunk 3800 chars\n",
        "        # Attempt to keep chunks > 2000 chars\n",
        "        \"max_characters\": 4000,\n",
        "        \"new_after_n_chars\": 3000,\n",
        "        \"combine_under_n_chars\": 2000,\n",
        "        \"split_pdf_allow_failed\": True,    # If True, the partitioning continues even if some pages fail.\n",
        "        \"split_pdf_concurrency_level\": 15  # Set the number of concurrent request to the maximum value: 15.\n",
        "    }\n",
        "}\n",
        "\n",
        "try:\n",
        "    res = client.general.partition(request=req)\n",
        "    if res.elements is None:\n",
        "      raise Exception('no file passed maybe')\n",
        "    element_dicts = [element for element in res.elements]\n",
        "\n",
        "    # Print the processed data's first element only.\n",
        "    print(element_dicts[0])\n",
        "\n",
        "    # Write the processed data to a local file.\n",
        "    json_elements = json.dumps(element_dicts, indent=2)\n",
        "\n",
        "    with open(f'{output_path}/{filename}.json', \"w\") as file:\n",
        "        file.write(json_elements)\n",
        "except (errors.HTTPValidationError, errors.ServerError) as e:\n",
        "    # handle e.data: errors.HTTPValidationErrorData\n",
        "    # handle e.data: errors.ServerErrorData\n",
        "    print(e.data)\n",
        "    raise(e)\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09cd727-aeab-49af-8a51-0dc377321e7c",
      "metadata": {
        "id": "b09cd727-aeab-49af-8a51-0dc377321e7c"
      },
      "source": [
        "We can examine the elements extracted by `partition_pdf`.\n",
        "\n",
        "`CompositeElement` are aggregated chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "628abfc6-4057-434b-b880-d88e3ba44657",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "628abfc6-4057-434b-b880-d88e3ba44657",
        "outputId": "ed2fae2f-09d6-4bf4-b8de-cc3882198311"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CompositeElement': 38, 'Table': 52}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Create a dictionary to store counts of each type\n",
        "category_counts = {}\n",
        "\n",
        "for element in res.elements:\n",
        "    category = element[\"type\"]\n",
        "    if category in category_counts:\n",
        "        category_counts[category] += 1\n",
        "    else:\n",
        "        category_counts[category] = 1\n",
        "\n",
        "# Unique_categories will have unique elements\n",
        "unique_categories = set(category_counts.keys())\n",
        "category_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5462f29e-fd59-4e0e-9493-ea3b560e523e",
      "metadata": {
        "id": "5462f29e-fd59-4e0e-9493-ea3b560e523e"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from typing import List\n",
        "from enum import Enum\n",
        "\n",
        "class Metadata(TypedDict):\n",
        "  text_as_html: str\n",
        "  page_number: int\n",
        "  languages: List[str]\n",
        "  filename: str\n",
        "\n",
        "class ElementType(str, Enum):\n",
        "  COMPOSITE = 'CompositeElement'\n",
        "  TABLE = 'Table'\n",
        "\n",
        "class Element(TypedDict):\n",
        "  type: ElementType\n",
        "  text: str\n",
        "  metadata: Metadata\n",
        "\n",
        "elements: List[Element]\n",
        "try:\n",
        "  elements = res.elements\n",
        "except Exception as e:\n",
        "  elements = json.load(open(f'{output_path}/{filename}.json'))\n",
        "\n",
        "table_elements = [e for e in elements if e[\"type\"] == ElementType.TABLE]\n",
        "text_elements = [e for e in elements if e['type'] == ElementType.COMPOSITE]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "731b3dfc-7ddf-4a11-9a30-9a79b7c66e16",
      "metadata": {
        "id": "731b3dfc-7ddf-4a11-9a30-9a79b7c66e16"
      },
      "source": [
        "## Multi-vector retriever\n",
        "\n",
        "Use [multi-vector-retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector#summary) to produce summaries of tables and, optionally, text.\n",
        "\n",
        "With the summary, we will also store the raw table elements.\n",
        "\n",
        "The summaries are used to improve the quality of retrieval, [as explained in the multi vector retriever docs](https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector).\n",
        "\n",
        "The raw tables are passed to the LLM, providing the full table context for the LLM to generate the answer.  \n",
        "\n",
        "### Summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8e275736-3408-4d7a-990e-4362c88e81f8",
      "metadata": {
        "id": "8e275736-3408-4d7a-990e-4362c88e81f8"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_community.chat_models import ChatPerplexity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b65677-aeb4-44fd-b06d-4539341ede97",
      "metadata": {
        "id": "37b65677-aeb4-44fd-b06d-4539341ede97"
      },
      "source": [
        "We create a simple summarize chain for each element.\n",
        "\n",
        "You can also see, re-use, or modify the prompt in the Hub [here](https://smith.langchain.com/hub/rlm/multi-vector-retriever-summarization).\n",
        "\n",
        "```\n",
        "from langchain import hub\n",
        "obj = hub.pull(\"rlm/multi-vector-retriever-summarization\")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1b12536a-1303-41ad-9948-4eb5a5f32614",
      "metadata": {
        "id": "1b12536a-1303-41ad-9948-4eb5a5f32614"
      },
      "outputs": [],
      "source": [
        "# Prompt\n",
        "prompt_text = \"\"\"You are an assistant tasked with summarizing tables. \\\n",
        "The text is in Japanese language, so feel free to translate to English before giving an output. \\\n",
        "The table format is in HTML. \\\n",
        "Give a concise summary of the table. Table: {element} \"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
        "\n",
        "# Summary chain\n",
        "model = ChatPerplexity(temperature=0, model=\"llama-3.1-sonar-large-128k-online\", pplx_api_key=userdata.get(\"PPLX_API_KEY\"))\n",
        "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8d8b567c-b442-4bf0-b639-04bd89effc62",
      "metadata": {
        "id": "8d8b567c-b442-4bf0-b639-04bd89effc62"
      },
      "outputs": [],
      "source": [
        "# Apply to tables\n",
        "tables = [i['metadata']['text_as_html'] for i in table_elements]\n",
        "table_summaries = summarize_chain.batch(tables[1:5], {\"max_concurrency\": 5})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for summary in table_summaries:\n",
        "  print(summary)\n",
        "  print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0ljrcxAcosJ",
        "outputId": "239638a1-70b9-4c88-d76d-1fdf7834b57e"
      },
      "id": "H0ljrcxAcosJ",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided table appears to be a statistical breakdown of various types of vehicle licenses or registrations in different Japanese prefectures. Here is a concise summary of the table:\n",
            "\n",
            "## Columns Explanation\n",
            "- **種類**: Type of vehicle license or registration.\n",
            "- **都道府**: Prefectures in Japan.\n",
            "- The subsequent columns represent different categories of vehicle licenses, including:\n",
            "  - **第二種免許** (Second-class license)\n",
            "  - **第一種免許** (First-class license)\n",
            "  - Various specific types such as **大型** (Large), **中型** (Medium), **普通** (Ordinary), **大型特殊** (Large special), etc.\n",
            "  - **小計** (Subtotal)\n",
            "  - Other specific categories like **中型垢** (Medium dirt), **準中型田垣** (Semi-medium field fence), etc.\n",
            "  - **原付** (Light vehicle or motorcycle)\n",
            "\n",
            "## Key Points\n",
            "- The table lists the number of vehicle licenses or registrations for each prefecture in Japan.\n",
            "- Each row represents a different prefecture, and the columns break down the numbers into various categories of vehicle licenses.\n",
            "- The data includes both general categories (e.g., large, medium, ordinary vehicles) and more specific categories (e.g., large special, light vehicles).\n",
            "\n",
            "## Example Data\n",
            "- For **北海道 (Hokkaido)**:\n",
            "  - **大型**: 94,344\n",
            "  - **中型**: 1,982\n",
            "  - **普通**: 23\n",
            "  - And so on for other categories.\n",
            "- Similar data is provided for other prefectures like **青森県 (Aomori Prefecture)**, **岩手県 (Iwate Prefecture)**, etc.\n",
            "\n",
            "This table is likely used to track and compare the distribution and types of vehicle licenses across different regions in Japan.\n",
            "---\n",
            "The provided table appears to be a collection of data related to various Japanese prefectures, but it is filled with numeric and symbolic placeholders (e.g., ⑤, ⑥, ⑦) instead of actual data. Here is a concise summary based on the structure and the few identifiable elements:\n",
            "\n",
            "## Summary\n",
            "\n",
            "- **Columns**: The table has multiple columns, but most of the data is represented by numeric and symbolic placeholders.\n",
            "- **Prefectures**: Each row represents a different Japanese prefecture, identified by their names in Kanji.\n",
            "  - Examples include:\n",
            "    - 静岡県 (Shizuoka Prefecture)\n",
            "    - 富山県 (Toyama Prefecture)\n",
            "    - 石川県 (Ishikawa Prefecture)\n",
            "    - 福井県 (Fukui Prefecture)\n",
            "    - 愛知県 (Aichi Prefecture)\n",
            "    - 京都府 (Kyoto Prefecture)\n",
            "    - 大阪府 (Osaka Prefecture)\n",
            "    - 兵庫県 (Hyogo Prefecture)\n",
            "    - 奈良県 (Nara Prefecture)\n",
            "    - 岡山県 (Okayama Prefecture)\n",
            "    - 広島県 (Hiroshima Prefecture)\n",
            "- **Data Columns**: The columns likely represent various statistical or administrative data points, such as area, population, or other metrics, but these are not clearly identifiable due to the placeholders.\n",
            "\n",
            "To provide a more accurate summary, the actual data would need to be filled in or translated from the placeholders. Here is an example of how it might look if the data were filled in, using the structure from the population statistics table in the first source:\n",
            "\n",
            "| Prefecture       | Area (km²) | Population (2022) |\n",
            "|------------------|------------|-------------------|\n",
            "| 静岡県 (Shizuoka) | 7,779      | 3,633,202         |\n",
            "| 富山県 (Toyama)  | 2,049      | 1,034,814         |\n",
            "| 石川県 (Ishikawa) | 4,186      | 1,132,526         |\n",
            "| 福井県 (Fukui)   | 4,191      | 766,863           |\n",
            "| 愛知県 (Aichi)   | 5,173      | 7,542,415         |\n",
            "| ...              | ...        | ...               |\n",
            "\n",
            "This example uses real data from the source on Japanese prefectures and major cities[1]. However, without the actual data filled in, the table remains largely incomprehensible.\n",
            "---\n",
            "The provided table appears to be a statistical summary of various Japanese prefectures, but it is complicated by the use of numeric and symbolic placeholders (e.g., ③, ④, etc.) instead of actual numbers and text. Here is a concise summary based on the interpretable parts of the table:\n",
            "\n",
            "## Prefectures and Key Statistics\n",
            "\n",
            "- **山口県 (Yamaguchi Prefecture)**\n",
            "  - Area: 7,539 km²\n",
            "  - Population and other statistics are obscured by symbols.\n",
            "\n",
            "- **徳島県 (Tokushima Prefecture)**\n",
            "  - Area: 6,681 km²\n",
            "  - Population: 177,658\n",
            "  - Other statistics are partially obscured.\n",
            "\n",
            "- **香川県 (Kagawa Prefecture)**\n",
            "  - Area: 6,440 km²\n",
            "  - Population: 523,212 (approximate, based on symbols)\n",
            "  - Other statistics are partially obscured.\n",
            "\n",
            "- **愛媛県 (Ehime Prefecture)**\n",
            "  - Area: 8,836 km²\n",
            "  - Population and other statistics are obscured by symbols.\n",
            "\n",
            "- **高知県 (Kochi Prefecture)**\n",
            "  - Area: 7,106 km²\n",
            "  - Population: 162,012\n",
            "  - Other statistics are partially obscured.\n",
            "\n",
            "- **福岡県 (Fukuoka Prefecture)**\n",
            "  - Area: Approximately 4,971 km² (based on context)\n",
            "  - Population and other statistics are obscured by symbols.\n",
            "\n",
            "- **長崎県 (Nagasaki Prefecture)**\n",
            "  - Area: 15,612 km²\n",
            "  - Population and other statistics are partially obscured.\n",
            "\n",
            "- **熊本県 (Kumamoto Prefecture)**\n",
            "  - Area: 14,170 km²\n",
            "  - Population: 398,083\n",
            "  - Other statistics are partially obscured.\n",
            "\n",
            "- **大分県 (Oita Prefecture)**\n",
            "  - Area: 7,568 km²\n",
            "  - Population and other statistics are partially obscured.\n",
            "\n",
            "- **宮崎県 (Miyazaki Prefecture)**\n",
            "  - Area: 6,627 km²\n",
            "  - Population and other statistics are partially obscured.\n",
            "\n",
            "- **鹿児島県 (Kagoshima Prefecture)**\n",
            "  - Area: 14,598 km²\n",
            "  - Population and other statistics are partially obscured.\n",
            "\n",
            "- **沖縄県 (Okinawa Prefecture)**\n",
            "  - Area: 19,730 km² (this seems incorrect; Okinawa's area is approximately 2,283 km²[4])\n",
            "  - Population: 288,598 (partial)\n",
            "  - Other statistics are partially obscured.\n",
            "\n",
            "## General Observations\n",
            "\n",
            "- The table includes various prefectures in Japan with their areas and population figures, among other statistics.\n",
            "- Many of the specific numbers are represented by symbols, making it difficult to provide a detailed summary.\n",
            "- The total row at the bottom suggests aggregated statistics for all prefectures, but these are also partially obscured.\n",
            "\n",
            "For accurate and detailed information, it would be necessary to replace the symbolic placeholders with actual numbers or translate the entire table into a readable format.\n",
            "---\n",
            "The provided table appears to be a statistical breakdown of the number of drivers holding different types of driver's licenses in various Japanese prefectures. Here is a concise summary of the table:\n",
            "\n",
            "## Table Summary\n",
            "\n",
            "### Columns\n",
            "- **種類 類 都 道 府 県**: Type of License and Prefecture\n",
            "- **第二種免許 一 種 免 詠**: Number of Second-Class Licenses for Large, Medium, Ordinary, Large Special, and Towing vehicles\n",
            "- **第一種免許 一 種 免 詐**: Number of First-Class Licenses for Medium, Semi-Medium, Ordinary, Large Special, Large Two-Wheel, Ordinary Two-Wheel, Small Special, and Miniature Vehicles\n",
            "- **合計 計**: Total Count\n",
            "\n",
            "### Key Points\n",
            "- The table lists the numbers of drivers holding different types of licenses in each prefecture.\n",
            "- **大型 (Large)**, **中型 (Medium)**, **普通 (Ordinary)**, **大型特殊 (Large Special)**, and **けん引 (Towing)** licenses are categorized under Second-Class Licenses.\n",
            "- **中型 (Medium)**, **準中型 (Semi-Medium)**, **普通 (Ordinary)**, **大型特殊 (Large Special)**, **大型二輪 (Large Two-Wheel)**, **普通二輪 (Ordinary Two-Wheel)**, **小型特殊 (Small Special)**, and **原付 (Miniature Vehicles)** licenses are categorized under First-Class Licenses.\n",
            "- Each row represents a different prefecture, with the corresponding numbers of license holders for each type of license.\n",
            "- The total count for each prefecture is also provided.\n",
            "\n",
            "### Example Data\n",
            "- **北海道 (Hokkaido)**:\n",
            "  - Second-Class Licenses: 2,424 (Large), 70 (Medium), 465 (Ordinary), 0 (Large Special), 0 (Towing)\n",
            "  - First-Class Licenses: 1,175,711 (Medium), 85,302 (Semi-Medium), etc.\n",
            "  - Total: 1,508,017\n",
            "\n",
            "This pattern continues for each prefecture listed in the table.\n",
            "\n",
            "### General Observations\n",
            "- The numbers vary significantly across different prefectures and types of licenses.\n",
            "- The table provides a detailed breakdown of the distribution of different types of driver's licenses across Japan, which can be useful for analyzing regional trends and license holder demographics.\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e9c176c-3d46-4034-b169-0d7305d42d27",
      "metadata": {
        "id": "3e9c176c-3d46-4034-b169-0d7305d42d27"
      },
      "outputs": [],
      "source": [
        "# Apply to texts\n",
        "texts = [i['text'] for i in text_elements]\n",
        "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 5})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60524010-754f-4924-ad75-78cb54ca7257",
      "metadata": {
        "id": "60524010-754f-4924-ad75-78cb54ca7257"
      },
      "source": [
        "### Add to vectorstore\n",
        "\n",
        "Use [Multi Vector Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector#summary) with summaries:\n",
        "\n",
        "* `InMemoryStore` stores the raw text, tables\n",
        "* `vectorstore` stores the embedded summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "346c3a02-8fea-4f75-a69e-fc9542b99dbc",
      "metadata": {
        "id": "346c3a02-8fea-4f75-a69e-fc9542b99dbc"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# The vectorstore to use to index the child chunks\n",
        "vectorstore = Chroma(collection_name=\"summaries\", embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "# The storage layer for the parent documents\n",
        "store = InMemoryStore()\n",
        "id_key = \"doc_id\"\n",
        "\n",
        "# The retriever (empty to start)\n",
        "retriever = MultiVectorRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    docstore=store,\n",
        "    id_key=id_key,\n",
        ")\n",
        "\n",
        "# Add texts\n",
        "doc_ids = [str(uuid.uuid4()) for _ in texts]\n",
        "summary_texts = [\n",
        "    Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
        "    for i, s in enumerate(text_summaries)\n",
        "]\n",
        "retriever.vectorstore.add_documents(summary_texts)\n",
        "retriever.docstore.mset(list(zip(doc_ids, texts)))\n",
        "\n",
        "# Add tables\n",
        "table_ids = [str(uuid.uuid4()) for _ in tables]\n",
        "summary_tables = [\n",
        "    Document(page_content=s, metadata={id_key: table_ids[i]})\n",
        "    for i, s in enumerate(table_summaries)\n",
        "]\n",
        "retriever.vectorstore.add_documents(summary_tables)\n",
        "retriever.docstore.mset(list(zip(table_ids, tables)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d8bbbd9-009b-4b34-a206-5874a60adbda",
      "metadata": {
        "id": "1d8bbbd9-009b-4b34-a206-5874a60adbda"
      },
      "source": [
        "## RAG\n",
        "\n",
        "Run [RAG pipeline](https://python.langchain.com/docs/expression_language/cookbook/retrieval)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2489de4-51e3-48b4-bbcd-ed9171deadf3",
      "metadata": {
        "id": "f2489de4-51e3-48b4-bbcd-ed9171deadf3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Prompt template\n",
        "template = \"\"\"Answer the question based only on the following context, which can include text and tables:\n",
        "{context}\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# LLM\n",
        "model = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
        "\n",
        "# RAG pipeline\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90e3d100-10e8-4ee6-ae46-2480b1524ec8",
      "metadata": {
        "id": "90e3d100-10e8-4ee6-ae46-2480b1524ec8",
        "outputId": "aa7ec732-74f7-4ef9-8e86-a015291701cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The number of training tokens for LLaMA2 is 2.0T.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"What is the number of training tokens for LLaMA2?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f46054-e239-4ba8-af81-22d0d6a9bc32",
      "metadata": {
        "id": "37f46054-e239-4ba8-af81-22d0d6a9bc32"
      },
      "source": [
        "We can check the [trace](https://smith.langchain.com/public/4739ae7c-1a13-406d-bc4e-3462670ebc01/r) to see what chunks were retrieved:\n",
        "\n",
        "This includes Table 1 of the paper, showing the Tokens used for training.\n",
        "\n",
        "```\n",
        "Training Data Params Context GQA Tokens LR Length 7B 2k 1.0T 3.0x 10-4 See Touvron et al. 13B 2k 1.0T 3.0 x 10-4 LiaMa 1 (2023) 33B 2k 14T 1.5 x 10-4 65B 2k 1.4T 1.5 x 10-4 7B 4k 2.0T 3.0x 10-4 Liama 2 A new mix of publicly 13B 4k 2.0T 3.0 x 10-4 available online data 34B 4k v 2.0T 1.5 x 10-4 70B 4k v 2.0T 1.5 x 10-4\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}